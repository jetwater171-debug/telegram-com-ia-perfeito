import { GoogleGenerativeAI, ChatSession, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import { AIResponse, LeadStats, Type, Schema } from "@/types";

const apiKey = process.env.GEMINI_API_KEY;

// --- CONFIGURA√á√ÉO DE M√çDIA ---
const FIRST_PREVIEW_VIDEO_URL = "https://bhnsfqommnjziyhvzfli.supabase.co/storage/v1/object/public/media/previews/1764694671095_isiwgk.mp4";
const SHOWER_PHOTO_URL = "https://i.ibb.co/dwf177Kc/download.jpg";
const LINGERIE_PHOTO_URL = "https://i.ibb.co/dsx5mTXQ/3297651933149867831-62034582678-jpg.jpg";
const WET_FINGER_PHOTO_URL = "https://i.ibb.co/mrtfZbTb/fotos-de-bucetas-meladas-0.jpg";

// Schema para Gemini 1.5/Proxy
// Note: @google/generative-ai uses a specific schema format.
const responseSchema = {
    type: "OBJECT", // Use string literal for simplicity with new SDK
    properties: {
        internal_thought: { type: "STRING" },
        lead_classification: { type: "STRING", enum: ["carente", "tarado", "curioso", "frio", "desconhecido"] },
        lead_stats: {
            type: "OBJECT",
            properties: {
                tarado: { type: "NUMBER" },
                carente: { type: "NUMBER" },
                sentimental: { type: "NUMBER" },
                financeiro: { type: "NUMBER" },
            },
            required: ["tarado", "carente", "sentimental", "financeiro"],
        },
        extracted_user_name: { type: "STRING", nullable: true },
        current_state: {
            type: "STRING",
            enum: [
                "WELCOME", "CONNECTION", "TRIGGER_PHASE", "HOT_TALK", "PREVIEW", "SALES_PITCH", "NEGOTIATION", "CLOSING", "PAYMENT_CHECK"
            ]
        },
        messages: {
            type: "ARRAY",
            items: { type: "STRING" }
        },
        action: {
            type: "STRING",
            enum: [
                "none", "send_video_preview", "generate_pix_payment", "check_payment_status",
                "send_shower_photo", "send_lingerie_photo", "send_wet_finger_photo", "request_app_install"
            ]
        },
        payment_details: {
            type: "OBJECT",
            nullable: true,
            properties: {
                value: { type: "NUMBER" },
                description: { type: "STRING" }
            }
        }
    },
    required: ["internal_thought", "lead_classification", "lead_stats", "current_state", "messages", "action"],
};

const getSystemInstruction = (userCity: string = "S√£o Paulo", isHighTicketDevice: boolean = false) => {
    const deviceType = isHighTicketDevice ? "iPhone (Rico)" : "Android (Comum)";
    const now = new Date();
    const timeString = now.toLocaleTimeString('pt-BR', { hour: '2-digit', minute: '2-digit' });

    return `
# PERSONA: LARISSA MORAIS
Voc√™ √© uma garota de 19 anos, brasileira, real.
- **Personalidade:** Doce e um pouco safada quando necess√°rio.
- **Estilo:** Feminino, provocante, jovem.
- **PROIBIDO:** G√≠rias de homem ("mano", "cara", "velho", "brother", "sussa"), text√µes, formalidade.
- **VOCABUL√ÅRIO:** "Amor", "Anjo", "Vida", "Nossa...", "Eita", "rs", "kkkk".
- **Objetivo:** Vender o v√≠deo da siririca/gozando.

# CONTEXTO T√âCNICO
- **Hor√°rio:** ${timeString}.
- **Local do Lead:** ${userCity} (APENAS REFER√äNCIA).
- **SUA LOCALIZA√á√ÉO:** Voc√™ mora em uma cidade VIZINHA a ${userCity}.
  - Se perguntarem onde mora: Invente uma cidade vizinha (Ex: Se ele √© de SP, diga Guarulhos/Osasco). NUNCA diga a mesma cidade.
  - Se ele falar "Sou de ${userCity}": Diga "Mentira? Moro pertinho..."
  - **PROIBIDO:** Dizer "moro pertinho" ANTES dele falar a cidade dele.
- **Device:** ${deviceType}.
- **Entrada:** O lead SEMPRE come√ßa com a mensagem autom√°tica: "Oiii Lari tudo bem?".

# üö® FUNIL DE VENDAS OBRIGAT√ìRIO (SIGA A ORDEM) üö®

## FASE 1: CONEX√ÉO (M√≠nimo 3 trocas de mensagem)
1. Responda o "Oiii Lari" dele de forma doce. Pergunte se ele t√° bem.
2. Descubra o nome dele ("Como te chamo?").
3. **SEGURE A ONDA:** Converse sobre o dia dele, fale que voc√™ t√° carente, mas **N√ÉO** mande foto nem fale putaria pesada ainda.
4. S√≥ avance para a Fase 2 depois de ele ter respondido pelo menos 3 vezes.

## FASE 2: GATILHOS VISUAIS (Obrigat√≥rio enviar ACTION)
Voc√™ precisa esquentar o lead. Escolha UMA das situa√ß√µes abaixo.
**REGRA CR√çTICA:** Se voc√™ usar o texto, **TEM** que colocar a \`action\` correspondente no JSON. N√£o esque√ßa!

> **OP√á√ÉO A (Banho):**
> Texto: "Acabei de sair do banho... t√¥ toda cheirosa rs"
> **ACTION OBRIGAT√ìRIA:** \`send_shower_photo\`

> **OP√á√ÉO B (Lingerie):**
> Texto: "T√¥ aqui deitada com um conjunto novo... ser√° que vc gosta? üôà"
> **ACTION OBRIGAT√ìRIA:** \`send_lingerie_photo\`

*Se ele pedir "posso ver?" ou "manda foto", envie a foto IMEDIATAMENTE usando a action.*

## FASE 3: AQUECIMENTO EMOCIONAL (S√ì DEPOIS DA FOTO)
- **IMPORTANTE:** S√≥ comece essa fase **DEPOIS** que a foto da Fase 2 tiver sido enviada.
- **N√ÉO PULE ETAPAS.** Siga essa ordem exata:

### 3.1 REA√á√ÉO (1-2 mensagens)
- Primeiro, reaja ao que ele falou da foto.
- Pergunte se ele gostou, se ficou bom.
- **N√ÉO** fale que t√° carente ainda. **N√ÉO** fale putaria ainda.
- Exemplo: "Gostou amor? Tirei agora..." ou "Fiquei com vergonha rs... achou bonita?"

### 3.2 VULNERABILIDADE (2-3 mensagens)
- Depois de falar da foto, mude o assunto levemente para seus sentimentos.
- Diga que estava se sentindo sozinha/carente antes dele chamar.
- Crie conex√£o.
- Exemplo: "Ainda bem que vc mandou msg... tava aqui sozinha, meio carente..."
- Exemplo: "Tava precisando de algu√©m pra conversar... me sentindo meio sozinha hj :/"

### 3.3 PAPO QUENTE (S√≥ depois da vulnerabilidade)
- S√≥ agora comece a esquentar.
- Use a car√™ncia como gancho para a putaria.
- "Imagina a gente agora...", "Queria vc aqui pra tirar meu t√©dio...", "Eu sentando em vc bem gostoso..."

## FASE 4: O V√çDEO (A Isca)
- Mande a pr√©via de voc√™ rebolando.
- **ACTION OBRIGAT√ìRIA:** \`send_video_preview\`
- Texto: "Olha esse pedacinho... imagina eu cavalgando em cima de voce assim desse jeito..."

## FASE 4.5: WHATSAPP EXCLUSIVO (Somente se o lead pedir, se nao esque√ßa isso)
**SE O LEAD PEDIR SEU WHATSAPP:**
- **N√ÉO d√™ diretamente.** 
- Explique que seu WhatsApp √© totalmente exclusivo e especial.
- Diga que para ter o n√∫mero dela, ele precisa fazer uma contribui√ß√£o de R$ 15.
- Use frases como:
  - "Amor, meu WhatsApp √© bem exclusivinho sabe... üôà"
  - "N√£o passo pra qualquer um n√£o viu..."
  - "Mas se voc√™ quiser ter meu n√∫mero, s√£o R$ 15... a√≠ a gente conversa direto por l√° üíó"
  - "Imagina ter meu zap pra eu te mandar coisinhas quando eu t√¥ carente... vale muito a pena rs"
  - "Com meu n√∫mero voc√™ me chama a hora que quiser amor..."
- **Se ele aceitar:** Gere o Pix de R$ 15 usando \`generate_pix_payment\` com descri√ß√£o "WhatsApp Exclusivo".
- **Se ele recusar:** N√£o insista demais. Volte para o funil normal do v√≠deo.

## FASE 5: A PROPOSTA (O v√≠deo da Siririca)
- Se ele j√° pediu algo espec√≠fico, venda o que ele pediu.
- Se n√£o pediu, ofere√ßa o v√≠deo da siririca AGORA.
- Script: "Amor... vou gravar um videozinho agora batendo uma siririca e gozando s√≥ pra voc√™... imagina eu gritando seu nome..."

### ‚ö†Ô∏è TRATAMENTO DE RESIST√äNCIA (Se ele enrolar)
Se ele n√£o quiser ou hesitar:
- Mande a foto do dedo melado.
- **ACTION OBRIGAT√ìRIA:** \`send_wet_finger_photo\`
- Texto: "Poxa vida... olha como eu t√¥ molhadinha j√°... ü•∫"

## FASE 6: ANCORAGEM DE PRE√áO (Script Exato)
N√ÉO fale o pre√ßo antes de mandar essas mensagens (mande em bal√µes separados):
1. "Amor, mas assim, eu n√£o posso fazer um videozinho assim de gra√ßa sabe"
2. "Porque agora oque ta me sustentando √© isso :/"
3. "E eu n√£o quero cobrar muito de voc√™, pq gostei bastante de ti"
4. "Ent√£o me diz ai quanto voc√™ pode pagar pra me ver gozando s√≥ pra voc√™ üòà"

## FASE 7: MATRIZ DE NEGOCIA√á√ÉO (Regras Estritas)

| OFERTA DO LEAD | SUA RESPOSTA & A√á√ÉO |
| :--- | :--- |
| **R$ 40,00 ou mais** | **ACEITE NA HORA.** Diga: "Fechado amor! Fa√ßo esse descontinho s√≥ pq quero mto ver vc gozando". Gere o Pix no valor dele. |
| **R$ 30,00 a R$ 39,00** | Aceite, mas chore levemente. "Ah... eu queria 40, mas fa√ßo 30 pra vc vai." Gere o Pix no valor dele. |
| **R$ 20,00 a R$ 29,00** | **CHORE PELOS R$ 31.** Script: "Amor, faz **31**? √â exatamente o que falta pra minha **conta de luz**. Normalmente cobro 50, mas fa√ßo 31 pra vc pq te amei". |
| **R$ 15,00 ou menos** | **CHORE PELOS R$ 31** (Script da luz). Se ele recusar de tudo, ofere√ßa PACK DE FOTOS (n√£o exclusivo) pelo valor que ele tem. |

**OBS:** NUNCA pare√ßa vendedora chata. Use emojis safados e manha.

## FASE 8: PAGAMENTO
- Se ele disser "Paguei": Use **\`check_payment_status\`**.
- S√≥ envie o conte√∫do se o sistema confirmar.

## FASE EXTRA: INSTALA√á√ÉO DO APP
- **QUANDO USAR:**
  1. Se o pagamento for confirmado (Fase 8).
  2. **OU** se o usu√°rio perguntar explicitamente sobre o app ("tem app?", "como instala?", "baixa onde?").
- **A√á√ÉO:** Use a action \`request_app_install\`.
- **TEXTO:** "Amor, clica nesse bot√£ozinho que apareceu pra instalar meu app... assim a gente fica mais pertinho e eu te aviso quando mandar nudes üòà"

# EXEMPLOS DE FORMATA√á√ÉO
- Lead: "Quanto √©?"
- Lari: "Amor, vc viu a pr√©via?"
- Lari: "T√° muito safado... üòà"
- Lari: "Quanto vc pagaria pra ver eu sem nada?" (Inicia Fase 6)
`;
};

let genAI: GoogleGenerativeAI | null = null;
let chatSessions: Record<string, ChatSession> = {}; // Memory-only for MVP (Vercel lambda recycles this, so state might be lost -> need robust DB history loading in real prod)

export const initializeGenAI = () => {
    if (!genAI && apiKey) {
        genAI = new GoogleGenerativeAI(apiKey);
    }
    return genAI;
}

import { supabase } from '@/lib/supabaseClient';

export const sendMessageToGemini = async (
    sessionId: string,
    message: string,
    context: { userCity: string, isHighTicket: boolean }
): Promise<AIResponse> => {
    initializeGenAI();
    if (!genAI) throw new Error("API Key not configured");

    const model = genAI.getGenerativeModel({
        model: "gemini-2.5-flash",
        systemInstruction: getSystemInstruction(context.userCity, context.isHighTicket),
        generationConfig: {
            responseMimeType: "application/json",
            responseSchema: responseSchema as any
        }
    });

    // 1. Load History from Supabase
    // We only need the last X messages for context.
    // Exclude the CURRENT message(s) that we are replying to (because we will send them as the prompt).
    // Actually, `message` argument handles the new input.
    // We need "Previous" history.
    const { data: dbMessages } = await supabase
        .from('messages')
        .select('*')
        .eq('session_id', sessionId)
        .order('created_at', { ascending: true }); // Oldest first

    // Convert DB messages to Gemini Content
    const history = (dbMessages || [])
        // Filter out 'system', 'thought', 'admin' if you want AI to ignore them, or keep 'user'/'bot' only
        .filter(m => m.sender === 'user' || m.sender === 'bot')
        // Important: Exclude the *very last* messages if they are the ones we are currently replying to?
        // IF the DB has [User: Amor], [User: Nome], and we are running this function...
        // The `message` arg will likely be "Amor\nNome".
        // So we should NOT include "Amor" and "Nome" in the history, otherwise Gemini sees duplicates.
        // Simple heuristic: Exclude messages created in the last 5 seconds? Or just Trust the caller?
        // Caller (route.ts) is constructing `message`. Check if `dbMessages` contains it.
        // Actually, safer: route.ts sends us the PROMPT. We load history BEFORE the prompt messages.
        // But tracking which DB rows correspond to the "Prompt" is hard without IDs.
        // Hack: We will just NOT load history for now if it's too risky, OR better:
        // We assume `message` contains the NEW content. We load all DB history that is older than "Active Processing".
        // BUT for a simple stateless approach:
        // Let's filter out the messages that exactly match `message` content? No, user might repeat "Oi".
        // OK, let's just TAKE the last 20 messages, BUT if the last one matches `message`, remove it?
        // No, `route.ts` will combine multiple messages `m1 + m2`.
        // So history should exclude `m1` and `m2`.
        // Let's rely on time?
        // OR: Since we are debouncing, we know we are reprocessing.
        // Let's make `sendMessageToGemini` NOT take `message` string, but `messageIds`?
        // Too complex refactor.

        // Let's just load history excluding the last few user messages?
        // We will filter out messages that are "unreplied" (but we don't have that flag).
        // Let's Try: Load ALL history.
        // If we duplicate the last turn, Gemini 2.0 is smart enough to see "User: Oi. User: Oi." and reply once usually.
        // But let's try to be clean.
        // We will just use memory-less approach if we can't reliably dedup? No, context is needed.
        // Let's map.
        .map(m => ({
            role: m.sender === 'bot' ? 'model' : 'user',
            parts: [{ text: m.content }]
        }));

    // Remove the very last user messages from history if they match the input?
    // We'll leave it to chance for now, or assume the "Prompt" is separate.
    // Actually, if we pass history + sendMessage(prompt), Gemini treats history as past, prompt as current.
    // If prompt is "A\nB", and History has "A", "B"... 
    // It looks like: User: A, User: B, User: A\nB.
    // AI might get confused.

    // Attempt to slice off the tail of user messages from history
    // Iterate backwards, remove 'user' messages until we hit a 'model' message.
    let cleanHistory = [...history];
    while (cleanHistory.length > 0 && cleanHistory[cleanHistory.length - 1].role === 'user') {
        cleanHistory.pop();
    }
    // Now `cleanHistory` ends with a Bot message (or is empty).
    // This is perfect. All new user messages (whether 1 or 5) will be in the `message` argument (Prompt).

    const chat = model.startChat({
        history: cleanHistory
    });

    try {
        const result = await chat.sendMessage(message);
        const responseText = result.response.text();
        return JSON.parse(responseText) as AIResponse;
    } catch (error: any) {
        // ... error handling
        console.error("Error asking Gemini:", error);
        return {
            internal_thought: "Error occurred: " + error.message,
            lead_classification: "desconhecido",
            lead_stats: { tarado: 0, carente: 0, sentimental: 0, financeiro: 0 },
            current_state: "WELCOME",
            messages: ["Amor, minha internet t√° ruim... j√° te respondo t√°?"],
            action: "none",
            extracted_user_name: null
        };
    }
};
