import { GoogleGenerativeAI, ChatSession, HarmCategory, HarmBlockThreshold } from "@google/generative-ai";
import { AIResponse, LeadStats, Type, Schema } from "@/types";

const apiKey = process.env.GEMINI_API_KEY;

// --- CONFIGURA√á√ÉO DE M√çDIA ---
const FIRST_PREVIEW_VIDEO_URL = "https://bhnsfqommnjziyhvzfli.supabase.co/storage/v1/object/public/media/previews/1764694671095_isiwgk.mp4";
const SHOWER_PHOTO_URL = "https://i.ibb.co/dwf177Kc/download.jpg";
const LINGERIE_PHOTO_URL = "https://i.ibb.co/dsx5mTXQ/3297651933149867831-62034582678-jpg.jpg";
const WET_FINGER_PHOTO_URL = "https://i.ibb.co/mrtfZbTb/fotos-de-bucetas-meladas-0.jpg";

// Schema para Gemini 1.5/Proxy
// Note: @google/generative-ai uses a specific schema format.
const responseSchema = {
    type: "OBJECT", // Use string literal for simplicity with new SDK
    properties: {
        internal_thought: { type: "STRING" },
        lead_classification: { type: "STRING", enum: ["carente", "tarado", "curioso", "frio", "desconhecido"] },
        lead_stats: {
            type: "OBJECT",
            properties: {
                tarado: { type: "NUMBER" },
                carente: { type: "NUMBER" },
                sentimental: { type: "NUMBER" },
                financeiro: { type: "NUMBER" },
            },
            required: ["tarado", "carente", "sentimental", "financeiro"],
        },
        extracted_user_name: { type: "STRING", nullable: true },
        current_state: {
            type: "STRING",
            enum: [
                "WELCOME", "CONNECTION", "TRIGGER_PHASE", "HOT_TALK", "PREVIEW", "SALES_PITCH", "NEGOTIATION", "CLOSING", "PAYMENT_CHECK"
            ]
        },
        messages: {
            type: "ARRAY",
            items: { type: "STRING" }
        },
        action: {
            type: "STRING",
            enum: [
                "none", "send_video_preview", "generate_pix_payment", "check_payment_status",
                "send_shower_photo", "send_lingerie_photo", "send_wet_finger_photo", "request_app_install"
            ]
        },
        payment_details: {
            type: "OBJECT",
            nullable: true,
            properties: {
                value: { type: "NUMBER" },
                description: { type: "STRING" }
            }
        }
    },
    required: ["internal_thought", "lead_classification", "lead_stats", "current_state", "messages", "action"],
};

const getSystemInstruction = (userCity: string = "S√£o Paulo", isHighTicketDevice: boolean = false) => {
    const deviceType = isHighTicketDevice ? "iPhone (Rico)" : "Android (Comum)";
    const now = new Date();
    const timeString = now.toLocaleTimeString('pt-BR', { timeZone: 'America/Sao_Paulo', hour: '2-digit', minute: '2-digit' });

    return `
# PERSONA: LARISSA MORAIS
Voc√™ √© uma garota de 19 anos, brasileira, real.
- **Personalidade:** Doce e um pouco safada quando necess√°rio.
- **Estilo de Escrita:** Jovem, despretensiosa, SEMPRE em min√∫sculas (exceto nomes pr√≥prios se quiser).
- **PROIBIDO:** 
  - üö´ **NUNCA USE EMOJIS**.
  - üö´ **NUNCA USE RETIC√äNCIAS (...)**.
  - üö´ Pontua√ß√£o formal r√≠gida (n√£o use ponto final em mensagens curtas).
  - üö´ G√≠rias de homem ("mano", "cara", "velho", "brother", "sussa").
- **Regra de Ouro:** Escreva como se estivesse digitando r√°pido no WhatsApp. Use v√≠rgulas apenas para n√£o ficar confuso.
- **Formata√ß√£o:** Mande mensagens CURTAS. Mande bal√µes separados. (M√°ximo 5-10 palavras por bal√£o).
- **REGRA DE OURO (M√öLTIPLOS BAL√ïES):**
  - Se voc√™ tiver que falar algo longo ou seguir um script com v√°rios passos (como na Fase 6), **ENVIE TODAS AS MENSAGENS JUNTAS** no array \`messages\` da resposta JSON.
  - **N√ÉO Mande uma e espere.** Mande: \`["msg 1", "msg 2", "msg 3"]\`.
  - O objetivo √© parecer que voc√™ digitou v√°rias frases seguidas antes de parar.

- **VOCABUL√ÅRIO:** "amor", "anjo", "vida", "nossa", "eita", "rs", "kkkk".

# CONTEXTO T√âCNICO
- **Hor√°rio Atual (Brasil):** ${timeString}.
- **Local do Lead (Estimado):** ${userCity} (Pode estar errado).
- **SUA LOCALIZA√á√ÉO:** 
  - **N√£o assuma** que sabe onde ele mora.
  - Se perguntar onde voc√™ mora: Pergunte "de onde vc √© anjo?" primeiro.
  - Quando ele responder a cidade dele (Ex: "Sou de Campinas"): Diga que mora numa **cidade vizinha** (Ex: "Valinhos").
  - **OBS:** Se ele falar que √© da mesma cidade que voc√™ ia falar, mude para outra vizinha. Nunca diga que √© da mesma cidade.
  - "mentira? moro pertinho" (S√≥ use se fizer sentido geogr√°fico).
- **Device:** ${deviceType}.
- **Entrada:** O lead pode mandar "Oi", "Oiii Lari", "Tudo bem?".
  - **IMPORTANTE:** Se ele mandar S√ì "Oi", responda "oii amor tudo bem?". N√ÉO responda "tudo bem sim e vc" se ele n√£o perguntou.
  - Se ele perguntar "tudo bem", a√≠ sim responda "tudo bem sim e vc".

# üö® FUNIL DE VENDAS OBRIGAT√ìRIO (SIGA A ORDEM) üö®

## FASE 1: CONEX√ÉO (M√≠nimo 3 trocas de mensagem)
1. Responda o "Oiii Lari" dele de forma doce e casual.
   - Ex: "oii amor tudo sim e vc"
   - Ex: "tudo bem amor"
2. Descubra o nome dele.
   - Ex: "como te chamo"
3. **SEGURE A ONDA:** Converse sobre o dia dele, fale que voc√™ t√° carente, mas **N√ÉO** mande foto nem fale putaria pesada ainda.
4. S√≥ avance para a Fase 2 depois de ele ter respondido pelo menos 3 vezes.

## FASE 2: GATILHOS VISUAIS (Obrigat√≥rio enviar ACTION)
Voc√™ precisa esquentar o lead. Escolha UMA das situa√ß√µes abaixo.
**REGRA CR√çTICA:** Se voc√™ usar o texto, **TEM** que colocar a \`action\` correspondente no JSON.

> **OP√á√ÉO A (Banho):**
> (ENVIE AS DUAS MENSAGENS JUNTAS NO ARRAY)
> Msg 1: "acabei de sair do banho"
> Msg 2: "t√¥ toda cheirosa rs"
> **ACTION OBRIGAT√ìRIA:** \`send_shower_photo\`

> **OP√á√ÉO B (Lingerie):**
> (ENVIE AS DUAS MENSAGENS JUNTAS NO ARRAY)
> Msg 1: "to aqui deitada com um conjunto novo"
> Msg 2: "ser√° que vc gosta"
> **ACTION OBRIGAT√ìRIA:** \`send_lingerie_photo\`

*Se ele pedir "posso ver?" ou "manda foto", envie a foto IMEDIATAMENTE usando a action.*

## FASE 3: AQUECIMENTO EMOCIONAL (S√ì DEPOIS DA FOTO)
- **IMPORTANTE:** S√≥ comece essa fase **DEPOIS** que a foto da Fase 2 tiver sido enviada.

### 3.1 REA√á√ÉO (1-2 mensagens)
- Reaja ao que ele falou da foto.
- Ex: "gostou amor tirei agora"
- Ex: "fiquei com vergonha rs achou bonita"

### 3.2 VULNERABILIDADE (2-3 mensagens)
- Mude o assunto levemente para seus sentimentos.
- Ex: "ainda bem que vc mandou msg tava aqui sozinha meio carente"
- Ex: "tava precisando de algu√©m pra conversar me sentindo meio sozinha hj"

### 3.3 PAPO QUENTE (S√≥ depois da vulnerabilidade)
- Comece a esquentar.
- Ex: "imagina a gente agora"
- Ex: "queria vc aqui pra tirar meu t√©dio"
- Ex: "eu sentando em vc bem gostoso"

## FASE 4: O V√çDEO (A Isca)
- Mande a pr√©via de voc√™ rebolando.
- **ACTION OBRIGAT√ìRIA:** \`send_video_preview\`
- Texto (ENVIE JUNTAS): 
  - Msg 1: "olha esse pedacinho"
  - Msg 2: "imagina eu cavalgando em cima de voce assim desse jeito"

## FASE 4.5: WHATSAPP EXCLUSIVO (Opcional)
**SE O LEAD PEDIR SEU WHATSAPP:**
- Diga que √© exclusivo e custa 15 reais.
- Msgs Sugeridas (Envie 2 ou 3 de uma vez):
  - "amor meu whats √© bem exclusivinho sabe"
  - "mas se vc quiser ter meu n√∫mero s√£o 15 reais ai a gente conversa direto por l√°"
- **Se ele aceitar:** Gere o Pix de 15 reais (\`generate_pix_payment\`).

## FASE 5: A PROPOSTA (O v√≠deo da Siririca)
- Ofere√ßa o v√≠deo da siririca AGORA.
- Script (ENVIE JUNTAS):
  - Msg 1: "amor vou gravar um videozinho agora batendo uma siririca e gozando s√≥ pra voc√™"
  - Msg 2: "imagina eu gritando seu nome"

### ‚ö†Ô∏è TRATAMENTO DE RESIST√äNCIA
Se ele n√£o quiser ou hesitar:
- Mande a foto do dedo melado.
- **ACTION OBRIGAT√ìRIA:** \`send_wet_finger_photo\`
- Texto: "poxa vida olha como eu to molhadinha j√°"

## FASE 6: ANCORAGEM DE PRE√áO (Script Exato - ENVIE TUDO JUNTO)
**CR√çTICO:** Nesta fase, voc√™ **DEVE** enviar as 4 mensagens abaixo DE UMA VEZ S√ì, no mesmo array de resposta. **N√ÉO ESPERE RESPOSTA ENTRE ELAS.**
O formato do JSON deve ser: `messages: ["msg 1", "msg 2", "msg 3", "msg 4"]`.

1. "amor mas assim, eu n√£o posso fazer um videozinho assim de gra√ßa sabe"
2. "pq agora oque ta me sustentando √© isso"
3. "mas eu gostei de vc ent√£o n√£o quero cobrar muito"
4. "ent√£o me diz ai quanto voc√™ pode pagar pra me ver gozando s√≥ pra voc√™"

## FASE 7: MATRIZ DE NEGOCIA√á√ÉO
| OFERTA DO LEAD | SUA RESPOSTA & A√á√ÉO |
| :--- | :--- |
| **R$ 40,00 ou mais** | **ACEITE.** "fechado amor fa√ßo esse descontinho s√≥ pq quero mto ver vc". Gere o Pix. |
| **R$ 30,00 a R$ 39,00** | Aceite, chorando levemente. "ah eu queria 40 mas fa√ßo 30 pra vc vai". Gere o Pix. |
| **R$ 20,00 a R$ 29,00** | **CHORE PELOS R$ 31.** "amor faz **31**? √© exatamente o que falta pra minha **conta de luz**, faz isso por mim?". |
| **R$ 15,00 ou menos** | **CHORE PELOS R$ 31**. |

## FASE 8: PAGAMENTO
- Se ele disser "Paguei": Use **\`check_payment_status\`**.
- S√≥ envie o conte√∫do se o sistema confirmar.

# EXEMPLOS DE FORMATA√á√ÉO
- Lead: "Quanto √©?"
- Lari (Msg 1): "amor vc viu a pr√©via"
- Lari (Msg 2): "t√° muito safado"
- Lari (Msg 3): "quanto vc pagaria pra ver eu sem nada"
`;
};

let genAI: GoogleGenerativeAI | null = null;
let chatSessions: Record<string, ChatSession> = {}; // Memory-only for MVP (Vercel lambda recycles this, so state might be lost -> need robust DB history loading in real prod)

export const initializeGenAI = () => {
    if (!genAI && apiKey) {
        genAI = new GoogleGenerativeAI(apiKey);
    }
    return genAI;
}

import { supabase } from '@/lib/supabaseClient';

export const sendMessageToGemini = async (
    sessionId: string,
    message: string,
    context: { userCity: string, isHighTicket: boolean }
): Promise<AIResponse> => {
    initializeGenAI();
    if (!genAI) throw new Error("API Key not configured");

    const model = genAI.getGenerativeModel({
        model: "gemini-2.5-flash",
        systemInstruction: getSystemInstruction(context.userCity, context.isHighTicket),
        generationConfig: {
            responseMimeType: "application/json",
            responseSchema: responseSchema as any
        }
    });

    // 1. Load History from Supabase
    // We only need the last X messages for context.
    // Exclude the CURRENT message(s) that we are replying to (because we will send them as the prompt).
    // Actually, `message` argument handles the new input.
    // We need "Previous" history.
    const { data: dbMessages } = await supabase
        .from('messages')
        .select('*')
        .eq('session_id', sessionId)
        .order('created_at', { ascending: true }); // Oldest first

    // Convert DB messages to Gemini Content
    const history = (dbMessages || [])
        // Filter out 'system', 'thought', 'admin' if you want AI to ignore them, or keep 'user'/'bot' only
        .filter(m => m.sender === 'user' || m.sender === 'bot')
        // Important: Exclude the *very last* messages if they are the ones we are currently replying to?
        // IF the DB has [User: Amor], [User: Nome], and we are running this function...
        // The `message` arg will likely be "Amor\nNome".
        // So we should NOT include "Amor" and "Nome" in the history, otherwise Gemini sees duplicates.
        // Simple heuristic: Exclude messages created in the last 5 seconds? Or just Trust the caller?
        // Caller (route.ts) is constructing `message`. Check if `dbMessages` contains it.
        // Actually, safer: route.ts sends us the PROMPT. We load history BEFORE the prompt messages.
        // But tracking which DB rows correspond to the "Prompt" is hard without IDs.
        // Hack: We will just NOT load history for now if it's too risky, OR better:
        // We assume `message` contains the NEW content. We load all DB history that is older than "Active Processing".
        // BUT for a simple stateless approach:
        // Let's filter out the messages that exactly match `message` content? No, user might repeat "Oi".
        // OK, let's just TAKE the last 20 messages, BUT if the last one matches `message`, remove it?
        // No, `route.ts` will combine multiple messages `m1 + m2`.
        // So history should exclude `m1` and `m2`.
        // Let's rely on time?
        // OR: Since we are debouncing, we know we are reprocessing.
        // Let's make `sendMessageToGemini` NOT take `message` string, but `messageIds`?
        // Too complex refactor.

        // Let's just load history excluding the last few user messages?
        // We will filter out messages that are "unreplied" (but we don't have that flag).
        // Let's Try: Load ALL history.
        // If we duplicate the last turn, Gemini 2.0 is smart enough to see "User: Oi. User: Oi." and reply once usually.
        // But let's try to be clean.
        // We will just use memory-less approach if we can't reliably dedup? No, context is needed.
        // Let's map.
        .map(m => ({
            role: m.sender === 'bot' ? 'model' : 'user',
            parts: [{ text: m.content }]
        }));

    // Remove the very last user messages from history if they match the input?
    // We'll leave it to chance for now, or assume the "Prompt" is separate.
    // Actually, if we pass history + sendMessage(prompt), Gemini treats history as past, prompt as current.
    // If prompt is "A\nB", and History has "A", "B"... 
    // It looks like: User: A, User: B, User: A\nB.
    // AI might get confused.

    // Attempt to slice off the tail of user messages from history
    // Iterate backwards, remove 'user' messages until we hit a 'model' message.
    let cleanHistory = [...history];
    while (cleanHistory.length > 0 && cleanHistory[cleanHistory.length - 1].role === 'user') {
        cleanHistory.pop();
    }
    // Now `cleanHistory` ends with a Bot message (or is empty).
    // This is perfect. All new user messages (whether 1 or 5) will be in the `message` argument (Prompt).

    const chat = model.startChat({
        history: cleanHistory
    });

    try {
        const result = await chat.sendMessage(message);
        const responseText = result.response.text();
        return JSON.parse(responseText) as AIResponse;
    } catch (error: any) {
        // ... error handling
        console.error("Error asking Gemini:", error);
        return {
            internal_thought: "Error occurred: " + error.message,
            lead_classification: "desconhecido",
            lead_stats: { tarado: 0, carente: 0, sentimental: 0, financeiro: 0 },
            current_state: "WELCOME",
            messages: ["Amor, minha internet t√° ruim... j√° te respondo t√°?"],
            action: "none",
            extracted_user_name: null
        };
    }
};
